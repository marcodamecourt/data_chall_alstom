{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un fichier .pkl\n",
    "def load_pkl_file(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Exemple de chemin de fichier .pkl\n",
    "file_path = \"dataset_trainA.pkl\"  # Remplacez par le chemin de votre fichier .pkl\n",
    "\n",
    "data = load_pkl_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbesses</th>\n",
       "      <th>Aimé Césaire</th>\n",
       "      <th>Alexandre Dumas</th>\n",
       "      <th>Alma - Marceau</th>\n",
       "      <th>Alésia</th>\n",
       "      <th>Anatole France</th>\n",
       "      <th>Anvers</th>\n",
       "      <th>Argentine</th>\n",
       "      <th>Arts et Métiers</th>\n",
       "      <th>Assemblée nationale</th>\n",
       "      <th>...</th>\n",
       "      <th>Villejuif - Paul Vaillant-Couturier</th>\n",
       "      <th>Villiers</th>\n",
       "      <th>Volontaires</th>\n",
       "      <th>Voltaire</th>\n",
       "      <th>Wagram</th>\n",
       "      <th>École Militaire</th>\n",
       "      <th>École vétérinaire de Maisons-Alfort</th>\n",
       "      <th>Église d'Auteuil</th>\n",
       "      <th>Église de Pantin</th>\n",
       "      <th>Étienne Marcel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbesses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aimé Césaire</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexandre Dumas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alma - Marceau</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alésia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>École Militaire</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>École vétérinaire de Maisons-Alfort</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Église d'Auteuil</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Église de Pantin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Étienne Marcel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Abbesses  Aimé Césaire  Alexandre Dumas  \\\n",
       "Abbesses                                  0.0           0.0              0.0   \n",
       "Aimé Césaire                              0.0           0.0              0.0   \n",
       "Alexandre Dumas                           0.0           0.0              0.0   \n",
       "Alma - Marceau                            0.0           0.0              0.0   \n",
       "Alésia                                    0.0           0.0              0.0   \n",
       "...                                       ...           ...              ...   \n",
       "École Militaire                           0.0           0.0              0.0   \n",
       "École vétérinaire de Maisons-Alfort       0.0           0.0              0.0   \n",
       "Église d'Auteuil                          0.0           0.0              0.0   \n",
       "Église de Pantin                          0.0           0.0              0.0   \n",
       "Étienne Marcel                            0.0           0.0              0.0   \n",
       "\n",
       "                                     Alma - Marceau  Alésia  Anatole France  \\\n",
       "Abbesses                                        0.0     0.0             0.0   \n",
       "Aimé Césaire                                    0.0     0.0             0.0   \n",
       "Alexandre Dumas                                 0.0     0.0             0.0   \n",
       "Alma - Marceau                                  0.0     0.0             0.0   \n",
       "Alésia                                          0.0     0.0             0.0   \n",
       "...                                             ...     ...             ...   \n",
       "École Militaire                                 0.0     0.0             0.0   \n",
       "École vétérinaire de Maisons-Alfort             0.0     0.0             0.0   \n",
       "Église d'Auteuil                                0.0     0.0             0.0   \n",
       "Église de Pantin                                0.0     0.0             0.0   \n",
       "Étienne Marcel                                  0.0     0.0             0.0   \n",
       "\n",
       "                                     Anvers  Argentine  Arts et Métiers  \\\n",
       "Abbesses                                0.0        0.0              0.0   \n",
       "Aimé Césaire                            0.0        0.0              0.0   \n",
       "Alexandre Dumas                         0.0        0.0              0.0   \n",
       "Alma - Marceau                          0.0        0.0              0.0   \n",
       "Alésia                                  0.0        0.0              0.0   \n",
       "...                                     ...        ...              ...   \n",
       "École Militaire                         0.0        0.0              0.0   \n",
       "École vétérinaire de Maisons-Alfort     0.0        0.0              0.0   \n",
       "Église d'Auteuil                        0.0        0.0              0.0   \n",
       "Église de Pantin                        0.0        0.0              0.0   \n",
       "Étienne Marcel                          0.0        0.0              0.0   \n",
       "\n",
       "                                     Assemblée nationale  ...  \\\n",
       "Abbesses                                             0.0  ...   \n",
       "Aimé Césaire                                         0.0  ...   \n",
       "Alexandre Dumas                                      0.0  ...   \n",
       "Alma - Marceau                                       0.0  ...   \n",
       "Alésia                                               0.0  ...   \n",
       "...                                                  ...  ...   \n",
       "École Militaire                                      0.0  ...   \n",
       "École vétérinaire de Maisons-Alfort                  0.0  ...   \n",
       "Église d'Auteuil                                     0.0  ...   \n",
       "Église de Pantin                                     0.0  ...   \n",
       "Étienne Marcel                                       0.0  ...   \n",
       "\n",
       "                                     Villejuif - Paul Vaillant-Couturier  \\\n",
       "Abbesses                                                             0.0   \n",
       "Aimé Césaire                                                         0.0   \n",
       "Alexandre Dumas                                                      0.0   \n",
       "Alma - Marceau                                                       0.0   \n",
       "Alésia                                                               0.0   \n",
       "...                                                                  ...   \n",
       "École Militaire                                                      0.0   \n",
       "École vétérinaire de Maisons-Alfort                                  0.0   \n",
       "Église d'Auteuil                                                     0.0   \n",
       "Église de Pantin                                                     0.0   \n",
       "Étienne Marcel                                                       0.0   \n",
       "\n",
       "                                     Villiers  Volontaires  Voltaire  Wagram  \\\n",
       "Abbesses                                  0.0          0.0       0.0     0.0   \n",
       "Aimé Césaire                              0.0          0.0       0.0     0.0   \n",
       "Alexandre Dumas                           0.0          0.0       0.0     0.0   \n",
       "Alma - Marceau                            0.0          0.0       0.0     0.0   \n",
       "Alésia                                    0.0          0.0       0.0     0.0   \n",
       "...                                       ...          ...       ...     ...   \n",
       "École Militaire                           0.0          0.0       0.0     0.0   \n",
       "École vétérinaire de Maisons-Alfort       0.0          0.0       0.0     0.0   \n",
       "Église d'Auteuil                          0.0          0.0       0.0     0.0   \n",
       "Église de Pantin                          0.0          0.0       0.0     0.0   \n",
       "Étienne Marcel                            0.0          0.0       0.0     0.0   \n",
       "\n",
       "                                     École Militaire  \\\n",
       "Abbesses                                         0.0   \n",
       "Aimé Césaire                                     0.0   \n",
       "Alexandre Dumas                                  0.0   \n",
       "Alma - Marceau                                   0.0   \n",
       "Alésia                                           0.0   \n",
       "...                                              ...   \n",
       "École Militaire                                  0.0   \n",
       "École vétérinaire de Maisons-Alfort              0.0   \n",
       "Église d'Auteuil                                 0.0   \n",
       "Église de Pantin                                 0.0   \n",
       "Étienne Marcel                                   0.0   \n",
       "\n",
       "                                     École vétérinaire de Maisons-Alfort  \\\n",
       "Abbesses                                                             0.0   \n",
       "Aimé Césaire                                                         0.0   \n",
       "Alexandre Dumas                                                      0.0   \n",
       "Alma - Marceau                                                       0.0   \n",
       "Alésia                                                               0.0   \n",
       "...                                                                  ...   \n",
       "École Militaire                                                      0.0   \n",
       "École vétérinaire de Maisons-Alfort                                  0.0   \n",
       "Église d'Auteuil                                                     0.0   \n",
       "Église de Pantin                                                     0.0   \n",
       "Étienne Marcel                                                       0.0   \n",
       "\n",
       "                                     Église d'Auteuil  Église de Pantin  \\\n",
       "Abbesses                                          0.0               0.0   \n",
       "Aimé Césaire                                      0.0               0.0   \n",
       "Alexandre Dumas                                   0.0               0.0   \n",
       "Alma - Marceau                                    0.0               0.0   \n",
       "Alésia                                            0.0               0.0   \n",
       "...                                               ...               ...   \n",
       "École Militaire                                   0.0               0.0   \n",
       "École vétérinaire de Maisons-Alfort               0.0               0.0   \n",
       "Église d'Auteuil                                  0.0               0.0   \n",
       "Église de Pantin                                  0.0               0.0   \n",
       "Étienne Marcel                                    0.0               0.0   \n",
       "\n",
       "                                     Étienne Marcel  \n",
       "Abbesses                                        0.0  \n",
       "Aimé Césaire                                    0.0  \n",
       "Alexandre Dumas                                 0.0  \n",
       "Alma - Marceau                                  0.0  \n",
       "Alésia                                          0.0  \n",
       "...                                             ...  \n",
       "École Militaire                                 0.0  \n",
       "École vétérinaire de Maisons-Alfort             0.0  \n",
       "Église d'Auteuil                                0.0  \n",
       "Église de Pantin                                0.0  \n",
       "Étienne Marcel                                  0.0  \n",
       "\n",
       "[307 rows x 307 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][\"flux_dégradé\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Abbesses  Aimé Césaire  Alexandre Dumas  \\\n",
      "Abbesses                                  0.0           0.0              0.0   \n",
      "Aimé Césaire                              0.0           0.0              0.0   \n",
      "Alexandre Dumas                           0.0           0.0              0.0   \n",
      "Alma - Marceau                            0.0           0.0              0.0   \n",
      "Alésia                                    0.0           0.0              0.0   \n",
      "...                                       ...           ...              ...   \n",
      "École Militaire                           0.0           0.0              0.0   \n",
      "École vétérinaire de Maisons-Alfort       0.0           0.0              0.0   \n",
      "Église d'Auteuil                          0.0           0.0              0.0   \n",
      "Église de Pantin                          0.0           0.0              0.0   \n",
      "Étienne Marcel                            0.0           0.0              0.0   \n",
      "\n",
      "                                     Alma - Marceau  Alésia  Anatole France  \\\n",
      "Abbesses                                        0.0     0.0             0.0   \n",
      "Aimé Césaire                                    0.0     0.0             0.0   \n",
      "Alexandre Dumas                                 0.0     0.0             0.0   \n",
      "Alma - Marceau                                  0.0     0.0             0.0   \n",
      "Alésia                                          0.0     0.0             0.0   \n",
      "...                                             ...     ...             ...   \n",
      "École Militaire                                 0.0     0.0             0.0   \n",
      "École vétérinaire de Maisons-Alfort             0.0     0.0             0.0   \n",
      "Église d'Auteuil                                0.0     0.0             0.0   \n",
      "Église de Pantin                                0.0     0.0             0.0   \n",
      "Étienne Marcel                                  0.0     0.0             0.0   \n",
      "\n",
      "                                     Anvers  Argentine  Arts et Métiers  \\\n",
      "Abbesses                                0.0        0.0              0.0   \n",
      "Aimé Césaire                            0.0        0.0              0.0   \n",
      "Alexandre Dumas                         0.0        0.0              0.0   \n",
      "Alma - Marceau                          0.0        0.0              0.0   \n",
      "Alésia                                  0.0        0.0              0.0   \n",
      "...                                     ...        ...              ...   \n",
      "École Militaire                         0.0        0.0              0.0   \n",
      "École vétérinaire de Maisons-Alfort     0.0        0.0              0.0   \n",
      "Église d'Auteuil                        0.0        0.0              0.0   \n",
      "Église de Pantin                        0.0        0.0              0.0   \n",
      "Étienne Marcel                          0.0        0.0              0.0   \n",
      "\n",
      "                                     Assemblée nationale  ...  \\\n",
      "Abbesses                                             0.0  ...   \n",
      "Aimé Césaire                                         0.0  ...   \n",
      "Alexandre Dumas                                      0.0  ...   \n",
      "Alma - Marceau                                       0.0  ...   \n",
      "Alésia                                               0.0  ...   \n",
      "...                                                  ...  ...   \n",
      "École Militaire                                      0.0  ...   \n",
      "École vétérinaire de Maisons-Alfort                  0.0  ...   \n",
      "Église d'Auteuil                                     0.0  ...   \n",
      "Église de Pantin                                     0.0  ...   \n",
      "Étienne Marcel                                       0.0  ...   \n",
      "\n",
      "                                     Villejuif - Paul Vaillant-Couturier  \\\n",
      "Abbesses                                                             0.0   \n",
      "Aimé Césaire                                                         0.0   \n",
      "Alexandre Dumas                                                      0.0   \n",
      "Alma - Marceau                                                       0.0   \n",
      "Alésia                                                               0.0   \n",
      "...                                                                  ...   \n",
      "École Militaire                                                      0.0   \n",
      "École vétérinaire de Maisons-Alfort                                  0.0   \n",
      "Église d'Auteuil                                                     0.0   \n",
      "Église de Pantin                                                     0.0   \n",
      "Étienne Marcel                                                       0.0   \n",
      "\n",
      "                                     Villiers  Volontaires  Voltaire  Wagram  \\\n",
      "Abbesses                                  0.0          0.0       0.0     0.0   \n",
      "Aimé Césaire                              0.0          0.0       0.0     0.0   \n",
      "Alexandre Dumas                           0.0          0.0       0.0     0.0   \n",
      "Alma - Marceau                            0.0          0.0       0.0     0.0   \n",
      "Alésia                                    0.0          0.0       0.0     0.0   \n",
      "...                                       ...          ...       ...     ...   \n",
      "École Militaire                           0.0          0.0       0.0     0.0   \n",
      "École vétérinaire de Maisons-Alfort       0.0          0.0       0.0     0.0   \n",
      "Église d'Auteuil                          0.0          0.0       0.0     0.0   \n",
      "Église de Pantin                          0.0          0.0       0.0     0.0   \n",
      "Étienne Marcel                            0.0          0.0       0.0     0.0   \n",
      "\n",
      "                                     École Militaire  \\\n",
      "Abbesses                                         0.0   \n",
      "Aimé Césaire                                     0.0   \n",
      "Alexandre Dumas                                  0.0   \n",
      "Alma - Marceau                                   0.0   \n",
      "Alésia                                           0.0   \n",
      "...                                              ...   \n",
      "École Militaire                                  0.0   \n",
      "École vétérinaire de Maisons-Alfort              0.0   \n",
      "Église d'Auteuil                                 0.0   \n",
      "Église de Pantin                                 0.0   \n",
      "Étienne Marcel                                   0.0   \n",
      "\n",
      "                                     École vétérinaire de Maisons-Alfort  \\\n",
      "Abbesses                                                             0.0   \n",
      "Aimé Césaire                                                         0.0   \n",
      "Alexandre Dumas                                                      0.0   \n",
      "Alma - Marceau                                                       0.0   \n",
      "Alésia                                                               0.0   \n",
      "...                                                                  ...   \n",
      "École Militaire                                                      0.0   \n",
      "École vétérinaire de Maisons-Alfort                                  0.0   \n",
      "Église d'Auteuil                                                     0.0   \n",
      "Église de Pantin                                                     0.0   \n",
      "Étienne Marcel                                                       0.0   \n",
      "\n",
      "                                     Église d'Auteuil  Église de Pantin  \\\n",
      "Abbesses                                          0.0               0.0   \n",
      "Aimé Césaire                                      0.0               0.0   \n",
      "Alexandre Dumas                                   0.0               0.0   \n",
      "Alma - Marceau                                    0.0               0.0   \n",
      "Alésia                                            0.0               0.0   \n",
      "...                                               ...               ...   \n",
      "École Militaire                                   0.0               0.0   \n",
      "École vétérinaire de Maisons-Alfort               0.0               0.0   \n",
      "Église d'Auteuil                                  0.0               0.0   \n",
      "Église de Pantin                                  0.0               0.0   \n",
      "Étienne Marcel                                    0.0               0.0   \n",
      "\n",
      "                                     Étienne Marcel  \n",
      "Abbesses                                        0.0  \n",
      "Aimé Césaire                                    0.0  \n",
      "Alexandre Dumas                                 0.0  \n",
      "Alma - Marceau                                  0.0  \n",
      "Alésia                                          0.0  \n",
      "...                                             ...  \n",
      "École Militaire                                 0.0  \n",
      "École vétérinaire de Maisons-Alfort             0.0  \n",
      "Église d'Auteuil                                0.0  \n",
      "Église de Pantin                                0.0  \n",
      "Étienne Marcel                                  0.0  \n",
      "\n",
      "[307 rows x 307 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0][\"flux_dégradé\"])  # Affiche la première paire de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour normaliser la matrice d'adjacence\n",
    "def normalize_adj(adj):\n",
    "    adj = adj + torch.eye(adj.size(0))  # Ajout des boucles propres (self-loops)\n",
    "    degree = torch.sum(adj, dim=1)\n",
    "    d_inv_sqrt = torch.pow(degree, -0.5).flatten()\n",
    "    d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.0\n",
    "    d_mat_inv_sqrt = torch.diag(d_inv_sqrt)\n",
    "    return torch.mm(torch.mm(d_mat_inv_sqrt, adj), d_mat_inv_sqrt)\n",
    "\n",
    "def normalize_features(features):\n",
    "    mean = torch.mean(features, dim=0)\n",
    "    std = torch.std(features, dim=0)\n",
    "    std[std == 0] = 1  # Évite la division par 0\n",
    "    normalized_features = (features - mean) / std\n",
    "    return normalized_features, mean, std\n",
    "\n",
    "def denormalize_output(output, mean, std):\n",
    "    return (output * std) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Masquer les valeurs où target == 0\n",
    "        mask = (targets != 0).float()  # Masque binaire : 1 si target != 0, sinon 0\n",
    "        \n",
    "        # Différence uniquement là où target != 0\n",
    "        diff = predictions - targets\n",
    "        \n",
    "        # Appliquer le masque\n",
    "        masked_diff = diff * mask\n",
    "        \n",
    "        # Calculer la somme des différences au carré (MSE) seulement pour les éléments valides\n",
    "        loss = torch.sum(masked_diff ** 2) / torch.sum(mask)  # Moyenne normalisée\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la couche GCN\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # Application de la normalisation et propagation\n",
    "        out = torch.matmul(adj, x)  # Multiplication par la matrice de connectivité\n",
    "        out = self.linear(out)  # Transformation linéaire\n",
    "        return F.relu(out)\n",
    "\n",
    "# Définition du modèle GCN complet\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim)  # Première couche\n",
    "        self.gcn2 = GCNLayer(hidden_dim, output_dim)  # Deuxième couche\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.gcn1(x, adj)  # Propagation dans la première couche\n",
    "        h = self.gcn2(h, adj)  # Propagation dans la deuxième couche\n",
    "        return h  # Sortie du modè\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.a = nn.Linear(2 * out_features, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.W(x)\n",
    "        N = h.size(0)\n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1)\n",
    "        e = F.leaky_relu(self.a(a_input).view(N, N))\n",
    "        attention = F.softmax(e.masked_fill(adj == 0, -1e9), dim=1)\n",
    "        h_prime = torch.matmul(attention, h)\n",
    "        return F.relu(h_prime)\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATLayer(input_dim, hidden_dim)\n",
    "        self.gat2 = GATLayer(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.gat1(x, adj)\n",
    "        h = self.gat2(h, adj)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des matrices d'adjacence\n",
    "normalized_adj_matrices = [normalize_adj(adj) for adj in adj_matrices]\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de validation\n",
    "train_ratio = 0.8\n",
    "num_train = int(len(normalized_adj_matrices) * train_ratio)\n",
    "\n",
    "train_adj = normalized_adj_matrices[:num_train]\n",
    "train_flux = flux_matrices[:num_train]  # Flux réels non normalisés\n",
    "val_adj = normalized_adj_matrices[num_train:]\n",
    "val_flux = flux_matrices[num_train:]  # Flux réels non normalisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3899/3346450516.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adj = torch.tensor(adj, dtype=torch.float32)\n",
      "/tmp/ipykernel_3899/3346450516.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flux = torch.tensor(flux, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN in model output!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Vérification des NaN dans les sorties et les pertes\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(output)\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in model output!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Rétropropagation\u001b[39;00m\n\u001b[1;32m     72\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAssertionError\u001b[0m: NaN in model output!"
     ]
    }
   ],
   "source": [
    "# Définition de l'appareil (CPU ou GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparamètres\n",
    "input_dim = adj_matrices[0].size(0)  # Nombre de nœuds\n",
    "hidden_dim = 64\n",
    "output_dim = flux_matrices[0].size(0)\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "# Initialisation du modèle, de la fonction de perte et de l'optimiseur\n",
    "model_gcn = GCN(input_dim, hidden_dim, output_dim).to(device)  # Transférer le modèle sur GPU\n",
    "criterion = CustomLoss().to(device)  # Transférer la fonction de perte sur GPU\n",
    "optimizer = optim.Adam(model_gcn.parameters(), lr=learning_rate)\n",
    "\n",
    "print(next(model_gcn.parameters()).device)  # Doit afficher 'cuda:0' si le GPU est utilisé\n",
    "\n",
    "# Transfert des données d'entraînement et de validation sur GPU\n",
    "train_adj = [adj.to(device) for adj in train_adj]\n",
    "train_flux = [flux.to(device) for flux in train_flux]\n",
    "val_adj = [adj.to(device) for adj in val_adj]\n",
    "val_flux = [flux.to(device) for flux in val_flux]\n",
    "\n",
    "# Création des DataLoader pour les ensembles d'entraînement et de validation\n",
    "train_dataset = TensorDataset(torch.stack(train_adj), torch.stack(train_flux))\n",
    "val_dataset = TensorDataset(torch.stack(val_adj), torch.stack(val_flux))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(epochs):\n",
    "    model_gcn.train()  # Mettre le modèle en mode entraînement\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_idx, (adj_batch, flux_batch) in enumerate(train_loader):\n",
    "        # Envoyer les lots sur le GPU\n",
    "        adj_batch = adj_batch.to(device)\n",
    "        flux_batch = flux_batch.to(device)\n",
    "\n",
    "        # Propagation avant\n",
    "        output = model_gcn(adj_batch, adj_batch)  # Utilisation des matrices d'adjacence\n",
    "        loss = criterion(output, flux_batch)  # Calcul de la perte\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Rétropropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation périodique\n",
    "    if epoch % 20 == 0:\n",
    "        model_gcn.eval()  # Mettre le modèle en mode évaluation\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():  # Pas de calcul des gradients pendant la validation\n",
    "            for adj_batch, flux_batch in val_loader:\n",
    "                adj_batch = adj_batch.to(device)\n",
    "                flux_batch = flux_batch.to(device)\n",
    "\n",
    "                output = model_gcn(adj_batch, adj_batch)\n",
    "                loss = criterion(output, flux_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {epoch_loss / len(train_loader)} | Val Loss: {val_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: nan | Val Loss: nan\n",
      "Epoch 20 | Train Loss: nan | Val Loss: nan\n",
      "Epoch 40 | Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj, flux \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_adj, train_flux):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Propagation avant\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, flux)\n\u001b[1;32m     22\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[0;32m---> 21\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Propagation dans la première couche\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(h, adj)  \u001b[38;5;66;03m# Propagation dans la deuxième couche\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Application de la normalisation et propagation\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Multiplication par la matrice de connectivité\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(out)  \u001b[38;5;66;03m# Transformation linéaire\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fonction pour prédire la matrice de flux\n",
    "def predict_flux(model, adj_matrix, device):\n",
    "    \"\"\"\n",
    "    Prédit la matrice de flux pour une matrice d'adjacence donnée.\n",
    "\n",
    "    Args:\n",
    "        model: Le modèle GCN entraîné.\n",
    "        adj_matrix: La matrice d'adjacence du graphe (Tensor).\n",
    "        device: L'appareil à utiliser (CPU ou GPU).\n",
    "    Returns:\n",
    "        Une matrice de flux prédite.\n",
    "    \"\"\"\n",
    "    model.eval()  # Mettre le modèle en mode évaluation\n",
    "\n",
    "    # Normalisation de la matrice d'adjacence\n",
    "    normalized_adj = normalize_adj(adj_matrix).to(device)  # Transfert sur GPU\n",
    "\n",
    "    # Créer un tenseur de caractéristiques initiales (par exemple, une matrice identité si aucun feature n’est donné)\n",
    "    x = torch.eye(normalized_adj.size(0)).to(device)  # Matrice identité sur GPU\n",
    "\n",
    "    with torch.no_grad():  # Pas de calcul de gradients\n",
    "        # Prédiction\n",
    "        output = model(x, normalized_adj)  # Passer les deux sur GPU\n",
    "        return output.cpu()  # Retour sur CPU pour analyse\n",
    "\n",
    "# Index du graphe que nous voulons analyser\n",
    "graph_index = 250  # Indices en Python commencent à 0, donc 251e élément correspond à index 250\n",
    "\n",
    "# Récupérer la matrice d'adjacence et de flux\n",
    "adj_matrix = adj_matrices[graph_index]\n",
    "flux_matrix = flux_matrices[graph_index]\n",
    "\n",
    "# Prédiction du flux\n",
    "predicted_flux = predict_flux(model_gcn, adj_matrix, device)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Matrice de flux réelle :\")\n",
    "print(flux_matrix)\n",
    "\n",
    "print(\"Matrice de flux prédite :\")\n",
    "print(predicted_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_names = data.iloc[graph_index][\"flux_dégradé\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion en numpy pour faciliter l'accès par indices\n",
    "flux_matrix_np = flux_matrix.numpy()\n",
    "predicted_flux_np = predicted_flux.numpy()\n",
    "\n",
    "erreur = 0\n",
    "n=0\n",
    "# Comparaison des valeurs là où flux_matrix != 0\n",
    "print(\"Comparaison des flux réels et prédits :\\n\")\n",
    "for i in range(flux_matrix_np.shape[0]):\n",
    "    for j in range(flux_matrix_np.shape[1]):\n",
    "        if flux_matrix_np[i, j] != 0:  # Vérifier uniquement les flux non nuls\n",
    "            real_value = flux_matrix_np[i, j]\n",
    "            predicted_value = predicted_flux_np[i, j]\n",
    "            erreur += abs(predicted_value-real_value)\n",
    "            n += 1\n",
    "            print(f\"De {station_names[i]} à {station_names[j]} :\")\n",
    "            print(f\"  Flux réel    : {real_value}\")\n",
    "            print(f\"  Flux prédit  : {predicted_value}\\n\")\n",
    "print('Erreur:',erreur/n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
