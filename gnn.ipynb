{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un fichier .pkl\n",
    "def load_pkl_file(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Exemple de chemin de fichier .pkl\n",
    "file_path = \"dataset_train.pkl\"  # Remplacez par le chemin de votre fichier .pkl\n",
    "\n",
    "data = load_pkl_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Abbesses  Aimé Césaire  Alexandre Dumas  Alma - Marceau  \\\n",
      "Abbesses               0.0           0.0              0.0             0.0   \n",
      "Aimé Césaire           0.0           0.0              0.0             0.0   \n",
      "Alexandre Dumas        0.0           0.0              0.0             0.0   \n",
      "Alma - Marceau         0.0           0.0              0.0             0.0   \n",
      "Alésia                 0.0           0.0              0.0             0.0   \n",
      "...                    ...           ...              ...             ...   \n",
      "Wagram                 0.0           0.0              0.0             0.0   \n",
      "École Militaire        0.0           0.0              0.0             0.0   \n",
      "Église d'Auteuil       0.0           0.0              0.0             0.0   \n",
      "Église de Pantin       0.0           0.0              0.0             0.0   \n",
      "Étienne Marcel         0.0           0.0              0.0             0.0   \n",
      "\n",
      "                  Alésia  Anatole France  Anvers  Argentine  Arts et Métiers  \\\n",
      "Abbesses             0.0             0.0     0.0        0.0              0.0   \n",
      "Aimé Césaire         0.0             0.0     0.0        0.0              0.0   \n",
      "Alexandre Dumas      0.0             0.0     0.0        0.0              0.0   \n",
      "Alma - Marceau       0.0             0.0     0.0        0.0              0.0   \n",
      "Alésia               0.0             0.0     0.0        0.0              0.0   \n",
      "...                  ...             ...     ...        ...              ...   \n",
      "Wagram               0.0             0.0     0.0        0.0              0.0   \n",
      "École Militaire      0.0             0.0     0.0        0.0              0.0   \n",
      "Église d'Auteuil     0.0             0.0     0.0        0.0              0.0   \n",
      "Église de Pantin     0.0             0.0     0.0        0.0              0.0   \n",
      "Étienne Marcel       0.0             0.0     0.0        0.0              0.0   \n",
      "\n",
      "                     Avron  ...  Villejuif - Louis Aragon  \\\n",
      "Abbesses          0.000000  ...                       0.0   \n",
      "Aimé Césaire      0.000000  ...                       0.0   \n",
      "Alexandre Dumas   5.145833  ...                       0.0   \n",
      "Alma - Marceau    0.000000  ...                       0.0   \n",
      "Alésia            0.000000  ...                       0.0   \n",
      "...                    ...  ...                       ...   \n",
      "Wagram            0.000000  ...                       0.0   \n",
      "École Militaire   0.000000  ...                       0.0   \n",
      "Église d'Auteuil  0.000000  ...                       0.0   \n",
      "Église de Pantin  0.000000  ...                       0.0   \n",
      "Étienne Marcel    0.000000  ...                       0.0   \n",
      "\n",
      "                  Villejuif - Léo Lagrange  Villiers  Volontaires  Voltaire  \\\n",
      "Abbesses                               0.0       0.0          0.0       0.0   \n",
      "Aimé Césaire                           0.0       0.0          0.0       0.0   \n",
      "Alexandre Dumas                        0.0       0.0          0.0       0.0   \n",
      "Alma - Marceau                         0.0       0.0          0.0       0.0   \n",
      "Alésia                                 0.0       0.0          0.0       0.0   \n",
      "...                                    ...       ...          ...       ...   \n",
      "Wagram                                 0.0       0.0          0.0       0.0   \n",
      "École Militaire                        0.0       0.0          0.0       0.0   \n",
      "Église d'Auteuil                       0.0       0.0          0.0       0.0   \n",
      "Église de Pantin                       0.0       0.0          0.0       0.0   \n",
      "Étienne Marcel                         0.0       0.0          0.0       0.0   \n",
      "\n",
      "                  Wagram  École Militaire  Église d'Auteuil  Église de Pantin  \\\n",
      "Abbesses             0.0              0.0               0.0               0.0   \n",
      "Aimé Césaire         0.0              0.0               0.0               0.0   \n",
      "Alexandre Dumas      0.0              0.0               0.0               0.0   \n",
      "Alma - Marceau       0.0              0.0               0.0               0.0   \n",
      "Alésia               0.0              0.0               0.0               0.0   \n",
      "...                  ...              ...               ...               ...   \n",
      "Wagram               0.0              0.0               0.0               0.0   \n",
      "École Militaire      0.0              0.0               0.0               0.0   \n",
      "Église d'Auteuil     0.0              0.0               0.0               0.0   \n",
      "Église de Pantin     0.0              0.0               0.0               0.0   \n",
      "Étienne Marcel       0.0              0.0               0.0               0.0   \n",
      "\n",
      "                  Étienne Marcel  \n",
      "Abbesses                     0.0  \n",
      "Aimé Césaire                 0.0  \n",
      "Alexandre Dumas              0.0  \n",
      "Alma - Marceau               0.0  \n",
      "Alésia                       0.0  \n",
      "...                          ...  \n",
      "Wagram                       0.0  \n",
      "École Militaire              0.0  \n",
      "Église d'Auteuil             0.0  \n",
      "Église de Pantin             0.0  \n",
      "Étienne Marcel               0.0  \n",
      "\n",
      "[261 rows x 261 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0][\"flux_dégradé\"])  # Affiche la première paire de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan de métro 1 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 2 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 3 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 4 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 5 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 6 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 7 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 8 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 9 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Plan de métro 10 :\n",
      "Adjacency Matrix Tensor :\n",
      " tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n",
      "Flux Matrix Tensor :\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([261, 261])\n"
     ]
    }
   ],
   "source": [
    "flux_matrices = []\n",
    "\n",
    "for i, (G, flux) in enumerate(zip(data[\"plan_metro_degradé\"], data[\"flux_dégradé\"])):\n",
    "    \n",
    "    # Convertir le graphe en une matrice d'adjacence\n",
    "    adj_matrix = nx.adjacency_matrix(G).todense()  # Convertir en format dense\n",
    "    \n",
    "    # Convertir la matrice d'adjacence en numpy\n",
    "    adj_matrix_np = np.array(adj_matrix)\n",
    "    \n",
    "    # Convertir la matrice de flux en numpy\n",
    "    flux_matrix_np = np.array(flux)\n",
    "    \n",
    "    # Convertir les matrices en tensor PyTorch\n",
    "    adj_tensor = torch.tensor(adj_matrix_np, dtype=torch.float32)\n",
    "    flux_tensor = torch.tensor(flux_matrix_np, dtype=torch.float32)\n",
    "    \n",
    "    # Ajouter les matrices dans les listes\n",
    "    adj_matrices.append(adj_tensor)  # Liste de matrices d'adjacence\n",
    "    flux_matrices.append(flux_tensor)  # Liste de matrices de flux\n",
    "    \n",
    "    # Optionnel : Afficher les matrices d'adjacence et de flux pour chaque plan\n",
    "    print(f\"Plan de métro {i + 1} :\")\n",
    "    print(f\"Adjacency Matrix Tensor :\\n\", adj_tensor)\n",
    "    print(adj_tensor.shape)\n",
    "    print(f\"Flux Matrix Tensor :\\n\", flux_tensor)\n",
    "    print(flux_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la couche GCN\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # Application de la normalisation et propagation\n",
    "        out = torch.matmul(adj, x)  # Multiplication par la matrice de connectivité\n",
    "        out = self.linear(out)  # Transformation linéaire\n",
    "        return F.relu(out)\n",
    "\n",
    "# Définition du modèle GCN complet\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim)  # Première couche\n",
    "        self.gcn2 = GCNLayer(hidden_dim, output_dim)  # Deuxième couche\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.gcn1(x, adj)  # Propagation dans la première couche\n",
    "        h = self.gcn2(h, adj)  # Propagation dans la deuxième couche\n",
    "        return h  # Sortie du modè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.a = nn.Linear(2 * out_features, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.W(x)\n",
    "        N = h.size(0)\n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1)\n",
    "        e = F.leaky_relu(self.a(a_input).view(N, N))\n",
    "        attention = F.softmax(e.masked_fill(adj == 0, -1e9), dim=1)\n",
    "        h_prime = torch.matmul(attention, h)\n",
    "        return F.relu(h_prime)\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATLayer(input_dim, hidden_dim)\n",
    "        self.gat2 = GATLayer(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.gat1(x, adj)\n",
    "        h = self.gat2(h, adj)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "input_dim = 1  # Exemple : nombre d'attributs par station\n",
    "hidden_dim = 64  # Dimension cachée\n",
    "output_dim = 221  # Flux de passagers entre chaque paire de stations\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Création du modèle GCN\n",
    "model_gcn = GCN(input_dim, hidden_dim, output_dim)\n",
    "model_gat = GAT(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Fonction de perte et optimiseur\n",
    "criterion = nn.MSELoss()  # Erreur quadratique moyenne\n",
    "optimizer1 = optim.Adam(model_gcn.parameters(), lr=learning_rate)\n",
    "optimizer2 = optim.Adam(model_gat.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entraînement\n",
    "epochs = 200\n",
    "\n",
    "# Exemple de données d'entrée : liste de matrices de caractéristiques et d'adjacence\n",
    "features_matrix = [torch.rand((221, input_dim)) for _ in range(10)]  # 10 instances, chaque avec 221 stations et 10 caractéristiques\n",
    "adj_list = [torch.rand((221, 221)) for _ in range(10)]  # 10 matrices de connectivité de taille 221x221\n",
    "\n",
    "# Exemple de cibles : matrices de flux réelles à prédire\n",
    "y = [torch.rand((221, 221)) for _ in range(10)]  # 10 matrices de flux réels de taille 221x221\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 0, Loss: 0.3333321809768677\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39221/2380190138.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features, dtype=torch.float32)  # Assurez-vous que 'features' est un Tensor\n",
      "/tmp/ipykernel_39221/2380190138.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adj = torch.tensor(adj, dtype=torch.float32)  # Assurez-vous que 'adj' est un Tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.3333321809768677\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Epoch 40, Loss: 0.3333321809768677\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Epoch 60, Loss: 0.3333321809768677\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "Epoch 80, Loss: 0.3333321809768677\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Epoch 100, Loss: 0.3333321809768677\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "Epoch 120, Loss: 0.3333321809768677\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "Epoch 140, Loss: 0.3333321809768677\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "Epoch 160, Loss: 0.3333321809768677\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "Epoch 180, Loss: 0.3333321809768677\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model_gcn.train()  # Mode entraînement\n",
    "    print(epoch)\n",
    "    optimizer1.zero_grad()  # Mise à zéro des gradients\n",
    "    \n",
    "    # Iterer à travers les matrices de caractéristiques et d'adjacence\n",
    "    for i in range(len(features_matrix)):\n",
    "        features = features_matrix[i]\n",
    "        adj = adj_list[i]\n",
    "        \n",
    "        features = torch.tensor(features, dtype=torch.float32)  # Assurez-vous que 'features' est un Tensor\n",
    "        adj = torch.tensor(adj, dtype=torch.float32)  # Assurez-vous que 'adj' est un Tensor\n",
    "        \n",
    "        # Propagation avant\n",
    "        output = model_gcn(features, adj)  # Prédiction des flux de passagers pour l'instance i\n",
    "        \n",
    "        # Calcul de la perte pour chaque matrice de flux\n",
    "        loss = criterion(output, y[i])\n",
    "        \n",
    "        # Rétropropagation et optimisation\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
